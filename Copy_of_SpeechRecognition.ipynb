{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SpeechRecognition",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuppohekar/Deep-Learning-Projects/blob/main/Copy_of_SpeechRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWg86WF_CNTT"
      },
      "source": [
        "!wget 'http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip'\r\n",
        "!unzip mini_speech_commands.zip\r\n",
        "!rm '/content/mini_speech_commands/README.md'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFcKymtMEdfy"
      },
      "source": [
        "import os\r\n",
        "import librosa\r\n",
        "import IPython.display as ipd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from scipy.io import wavfile\r\n",
        "import warnings\r\n",
        "\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X39fSGejEBJY"
      },
      "source": [
        "path = '/content/mini_speech_commands/up/0132a06d_nohash_2.wav'\r\n",
        "soundnumpy, _ = librosa.load(path, \r\n",
        "             sr=16000,\r\n",
        "             mono=True,\r\n",
        "             offset=0.0,\r\n",
        "             duration=None, \r\n",
        "             dtype=np.float32, \r\n",
        "             res_type='kaiser_best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf598eGIFJii"
      },
      "source": [
        "soundnumpy.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi7xzZmBFjBV"
      },
      "source": [
        "plt.plot(soundnumpy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTH9_FPvG_yq"
      },
      "source": [
        "#Create a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWgYpLomHBm0"
      },
      "source": [
        "X = []\r\n",
        "y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28Tnv2vpHI1m"
      },
      "source": [
        "folders = ['down','go','left','no','right','stop','up','yes']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-NGmTzKHYK1"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "import os \r\n",
        "\r\n",
        "path = '/content/mini_speech_commands'\r\n",
        "for i in folders:\r\n",
        "  for audio in tqdm(os.listdir(path+'/'+i)):\r\n",
        "    filepath=os.path.join(path+'/'+i+'/'+audio)\r\n",
        "    samples, _ = librosa.load(path=filepath, sr=16000)\r\n",
        "    if(len(samples)==16000):\r\n",
        "      X.append(samples)\r\n",
        "      y.append(i)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5euHZ5NNKoH"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from keras.utils import np_utils\r\n",
        "\r\n",
        "X = np.array(X)\r\n",
        "y = np.array(y)\r\n",
        "le = LabelEncoder()\r\n",
        "y = le.fit_transform(y)\r\n",
        "y = np_utils.to_categorical(y, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suqFWB5xPoQ3"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs05lo9rM-EH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXRTz4TRL-Wi"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(units=10000, activation='relu', input_dim=16000))\r\n",
        "model.add(Dense(units=8, activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAos5ejrNCx6"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\r\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\r\n",
        "filepath='bestweights.h5'\r\n",
        "mc = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\r\n",
        "rd = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyR1cXtjNlIf"
      },
      "source": [
        "model.fit(x=X_train, y=y_train, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}